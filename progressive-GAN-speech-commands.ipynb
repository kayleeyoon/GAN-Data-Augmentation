{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, AveragePooling2D, Add, Layer\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, save_model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from librosa.output import write_wav\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'down'\n",
    "img_shape = (128, 32, 1) # rows, columns, channels\n",
    "latent_dim = 100\n",
    "power = .5\n",
    "sr = 16000\n",
    "model_sizes = [(16, 4, 1), (32, 8, 1), (64, 16, 1), (128, 32, 1)]\n",
    "batch_size = 32\n",
    "n_epochs = 30\n",
    "g_lr = .0001\n",
    "d_lr = .0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/' + command + '-train.npy')\n",
    "_max = np.amax(X_train)\n",
    "\n",
    "# normalize\n",
    "X_train = X_train / _max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name='ws_alpha')\n",
    "\n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel-wise feature vector normalization layer\n",
    "class PixelNormalization(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # calculate square pixel values\n",
    "        values = inputs**2.0\n",
    "        # calculate the mean pixel values\n",
    "        mean_values = backend.mean(values, axis=-1, keepdims=True)\n",
    "        # ensure the mean is not zero\n",
    "        mean_values += 1.0e-8\n",
    "        # calculate the sqrt of the mean squared value (L2 norm)\n",
    "        l2 = backend.sqrt(mean_values)\n",
    "        # normalize values by the l2 norm\n",
    "        normalized = inputs / l2\n",
    "        return normalized\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator():\n",
    "    # initialize weights\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # set a weight constraint\n",
    "    const = max_norm(1.0)\n",
    "    model_list = []\n",
    "    \n",
    "    in_image = Input(shape=model_sizes[0])\n",
    "\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "    \n",
    "    model = Model(in_image, out_class)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=Adam(lr=d_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    # create submodels\n",
    "    for i in range(1, len(model_sizes)):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        \n",
    "        # create new model for next resolution\n",
    "        models = add_discriminator_block(old_model, i)\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_discriminator_block(old_model, i, n_input_layers=3):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    # get shape of existing model\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    \n",
    "    # define new input shape\n",
    "    input_shape = model_sizes[i]\n",
    "    \n",
    "    in_image = Input(shape=input_shape)\n",
    "   \n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = AveragePooling2D()(d)\n",
    "    block_new = d\n",
    "    \n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model1 = Model(in_image, d)\n",
    "    model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=d_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    \n",
    "    # downsample the new larger image\n",
    "    downsample = AveragePooling2D()(in_image)\n",
    "    \n",
    "    # connect old input processing to downsampled new input\n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    \n",
    "    # fade in output of old model input layer with new input\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    \n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model2 = Model(in_image, d)\n",
    "    model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=d_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = []\n",
    "    \n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    g  = Dense(128 * model_sizes[0][0] * model_sizes[0][1], kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((model_sizes[0][0], model_sizes[0][1], 128))(g)\n",
    "    \n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    out_image = Conv2D(1, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const, activation='sigmoid')(g)\n",
    "    \n",
    "    model = Model(in_latent, out_image)\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    # create submodels\n",
    "    for i in range(1, len(model_sizes)):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "        models = add_generator_block(old_model)\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generator_block(old_model):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    \n",
    "    # get the end of the last block\n",
    "    block_end = old_model.layers[-2].output\n",
    "    \n",
    "    # upsample, and define new block\n",
    "    upsampling = UpSampling2D()(block_end)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    out_image = Conv2D(1, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const, activation='sigmoid')(g)\n",
    "    \n",
    "    model1 = Model(old_model.input, out_image)\n",
    "    \n",
    "    # get the output layer from old model\n",
    "    out_old = old_model.layers[-1]\n",
    "    # connect the upsampling to the old output layer\n",
    "    out_image2 = out_old(upsampling)\n",
    "    # define new output image as the weighted sum of the old and new models\n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    \n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_composite(discriminators, generators):\n",
    "    model_list = []\n",
    "    \n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "        \n",
    "        # straight-through model\n",
    "        d_models[0].trainable = False\n",
    "        model1 = Sequential()\n",
    "        model1.add(g_models[0])\n",
    "        model1.add(d_models[0])\n",
    "        model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=g_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        \n",
    "        # fade-in model\n",
    "        d_models[1].trainable = False\n",
    "        model2 = Sequential()\n",
    "        model2.add(g_models[1])\n",
    "        model2.add(d_models[1])\n",
    "        model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=g_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        \n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    i = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[i]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, n_samples):\n",
    "    noise = np.random.normal(0, 1, (n_samples, latent_dim))\n",
    "    generated_image = generator.predict(noise)\n",
    "    y = -np.ones((n_samples, 1))\n",
    "    return generated_image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fadein(models, step, n_steps):\n",
    "    # calculate current alpha (linear from 0 to 1)\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    # update the alpha for each model\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_models, d_models, gan_models, dataset, latent_dim):\n",
    "    # fit the baseline model\n",
    "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "    \n",
    "    # scale dataset to appropriate size\n",
    "    gen_shape = g_normal.output_shape\n",
    "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "    print('Data Size:', scaled_data.shape)\n",
    "    \n",
    "    # train normal or straight-through models\n",
    "    train_epochs(g_normal, d_normal, gan_normal, scaled_data)\n",
    "    save_images('tuned', gen_shape, g_normal)\n",
    "    \n",
    "    for i in range(1, len(g_models)):\n",
    "        # retrieve models for this level of growth\n",
    "        [g_normal, g_fadein] = g_models[i]\n",
    "        [d_normal, d_fadein] = d_models[i]\n",
    "        [gan_normal, gan_fadein] = gan_models[i]\n",
    "        # scale dataset to appropriate size\n",
    "        gen_shape = g_normal.output_shape\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        print('Data Size:', scaled_data.shape)\n",
    "        # train fade-in models for next level of growth\n",
    "        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, True)\n",
    "        save_images('faded', gen_shape, g_fadein)\n",
    "        # train normal or straight-through models\n",
    "        train_epochs(g_normal, d_normal, gan_normal, scaled_data)\n",
    "        save_images('tuned', gen_shape, g_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(g_model, d_model, gan_model, dataset, fadein=False):\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = int(dataset.shape[0] / batch_size) * n_epochs\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        # update alpha for all WeightedSum layers when fading in new blocks\n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
    "        \n",
    "        X_real, y_real = generate_real_samples(dataset, batch_size)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, batch_size)\n",
    "        \n",
    "        # update discriminator model\n",
    "        d_loss_real = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss_fake = d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        y_real2 = np.ones((batch_size, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        \n",
    "    print('dreal=%.2f, dfake=%.2f, g=%.2f' % (d_loss_real, d_loss_fake, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(model, epoch):\n",
    "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "    generated_images = model.predict(noise)\n",
    "    generated_image = np.squeeze(generated_images[0])\n",
    "    audio = librosa.feature.inverse.mel_to_audio(denormalize(generated_image), sr=sr, power=power)\n",
    "    write_wav('audio/' + command + '_' + str(epoch) + '.wav', sr=sr, y=audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(status, gen_shape, generator):\n",
    "    rows, cols = 2, 2\n",
    "    noise = np.random.normal(0, 1, (rows * cols, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols)\n",
    "    cnt = 1\n",
    "    for i in range(rows * cols):\n",
    "        plt.subplot(rows, cols, cnt)\n",
    "        librosa.display.specshow(gen_imgs[i, :,:,0])\n",
    "        cnt += 1\n",
    "    name = 'images/%02dx%02d-%s' % (gen_shape[1], gen_shape[2], status)\n",
    "    fig.savefig(name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(gan, generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    save_model(gan, './saved_models/gan')\n",
    "    discriminator.trainable = True\n",
    "    save_model(generator, './saved_models/generator')\n",
    "    save_model(discriminator, './saved_models/discriminator')\n",
    "\n",
    "def load():\n",
    "    discriminator = load_model('./saved_models/discriminator')\n",
    "    generator = load_model('./saved_models/generator')\n",
    "    gan = load_model('./saved_models/gan')\n",
    "    gan.summary()\n",
    "    discriminator.summary()\n",
    "    generator.summary()\n",
    "\n",
    "    return gan, generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(array):\n",
    "    return (array * _max) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_models = define_discriminator()\n",
    "g_models = define_generator()\n",
    "gan_models = define_composite(d_models, g_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(g_models, d_models, gan_models, X_train, latent_dim,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "generated_image = g_models[3][0].predict(noise)\n",
    "generated_image = np.squeeze(generated_image)\n",
    "librosa.display.specshow(generated_image)\n",
    "\n",
    "test = librosa.feature.inverse.mel_to_audio(denormalize(generated_image), sr=sr, power=power)\n",
    "#write_wav('test.wav', sr=sr, y=test)\n",
    "ipd.Audio(test, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(g_model, d_model, gan_model, epochs, progress_interval, save_interval):\n",
    "    scaled_data = scale_dataset(X_train, (128, 32, 1))\n",
    "    for epoch in range(epochs):\n",
    "        X_real, y_real = generate_real_samples(scaled_data, batch_size)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, batch_size)\n",
    "        \n",
    "        # update discriminator model\n",
    "        d_loss_real = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss_fake = d_model.train_on_batch(X_fake, y_fake)\n",
    "        acc = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        y_real2 = np.ones((batch_size, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        \n",
    "        if epoch % progress_interval == 0:\n",
    "            print(str(epoch) + ' dreal=%.5f, dfake=%.5f, g=%.5f' % (d_loss_real, d_loss_fake, g_loss))\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            save_images('final' + str(epoch), (16, 128, 32), g_model)\n",
    "            #save_audio(g_model, epoch)\n",
    "                   \n",
    "    return g_model, d_model, gan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = g_models[3][0]\n",
    "discriminator = d_models[3][0]\n",
    "gan = gan_models[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator, gan = train_final_model(generator, discriminator, gan, 151, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "generated_image = generator.predict(noise)\n",
    "generated_image = np.squeeze(generated_image)\n",
    "librosa.display.specshow(generated_image)\n",
    "\n",
    "test = librosa.feature.inverse.mel_to_audio(denormalize(generated_image), sr=sr, power=power)\n",
    "#write_wav('test.wav', sr=sr, y=test)\n",
    "ipd.Audio(test, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(n, generator):\n",
    "    noise = np.random.normal(0, 1, (n, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        generated_image = np.squeeze(generated_images[i])\n",
    "        img = librosa.feature.inverse.mel_to_audio(generated_image, sr=sr, power=power)\n",
    "        write_wav('./data/speech_clips/generated/' + command + '_' + str(i) + '.wav', sr=sr, y=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_audio(1500, generator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "real = resize(X_train[4],  (128, 32, 1), 0)\n",
    "librosa.display.specshow(np.squeeze(real))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "real = np.squeeze(X_train[0])\n",
    "librosa.display.specshow(real)\n",
    "test = librosa.feature.inverse.mel_to_audio(denormalize(real), sr=sr, power=power)\n",
    "write_wav('baseline.wav', sr=sr, y=test)\n",
    "ipd.Audio(test, rate=sr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def prep_data():\n",
    "    spectrograms = []\n",
    "    file = os.listdir('./data/speech_clips/' + command)\n",
    "    for file in os.listdir('./data/speech_clips/' + command + '/'):\n",
    "        split_filename = file.split('.')\n",
    "        if split_filename[1] == 'wav':\n",
    "            data, rate = librosa.load('./data/speech_clips/'  + command + '/' + file, duration=1, sr=sr)\n",
    "            spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128, power=power)\n",
    "            if spectrogram.shape[1] == 32:\n",
    "                spectrograms.append(spectrogram)\n",
    "\n",
    "    X_train = np.array(spectrograms)\n",
    "    np.random.shuffle(X_train)\n",
    "    X_test = X_train[:600]\n",
    "    X_train = X_train[600:]\n",
    "    \n",
    "    np.save('./data/' + command + '-train',  X_train)\n",
    "    np.save('./data/' + command + '-test',  X_train)\n",
    "    return spectrogram.shape\n",
    "\n",
    "shape = prep_data()\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
