{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from tensorflow.keras.layers import Dropout, Dense, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (128, 32, 1) # rows, columns, channels\n",
    "power = .5\n",
    "sr = 16000\n",
    "commands = [ 'no', 'stop','yes', 'up', 'down', 'left', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(datatype):\n",
    "    global _max\n",
    "    y = []\n",
    "    command_num = 0\n",
    "    for command in commands:\n",
    "        command_data = np.load('./data/' + command + '-' + datatype + '.npy', allow_pickle=True)\n",
    "        for _ in range(command_data.shape[0]):\n",
    "            y.append(command_num)\n",
    "        if command_num == 0:\n",
    "            X = command_data\n",
    "        else:\n",
    "            X = np.concatenate((X, command_data), axis=0)\n",
    "        command_num += 1   \n",
    "    \n",
    "    # add generated data to training dataset \n",
    "    if datatype == 'train':\n",
    "        generated_data = np.load('./data/speech-commands-generated-data.npy', allow_pickle=True)\n",
    "        X_generated, y_generated = zip(*generated_data)\n",
    "        #X = np.concatenate((X, X_generated), axis=0)\n",
    "        X = X_generated\n",
    "        y = y + list(y_generated)\n",
    "   \n",
    "    # one hot encode target output\n",
    "    y = np.array(keras.utils.to_categorical(y, len(commands)))\n",
    "    \n",
    "    # normalize\n",
    "    X = np.expand_dims(X, axis=3)\n",
    "    _max = np.amax(X)\n",
    "    X = X / _max\n",
    "    \n",
    "    return shuffle(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = prepare_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=(img_shape)))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(len(commands), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, verbose=2, epochs=15, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionList = []\n",
    "actualList = []\n",
    "for pred in predictions:\n",
    "    predictionList.append(np.argmax(pred))\n",
    "for actual in y_test:\n",
    "    actualList.append(np.argmax(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(predictionList)):\n",
    "    if predictionList[i] == actualList[i]:\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(correct/total, 4) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "no, stop, yes, up, down, left, right\n",
    "generated_0 = [0.9037]\n",
    "generated_150 = []\n",
    "generated_300 = []\n",
    "generated_500 = []\n",
    "generated_750 = []\n",
    "generated_1000 = []\n",
    "generated_1250 = []\n",
    "generated_1500 = [0.8973]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for results in [generated_0, generated_250, generated_500, generated_750, generated_1000, generated_1250, generated_1500]:\n",
    "    print('i: %4d, mean: %2.3f, standard deviation: %0.3f' %(i, np.mean(results), np.std(results)))  \n",
    "    i += 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title=None, cmap=plt.cm.Blues):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(actualList, predictionList, classes=commands, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_with_label = {'no':[0, 0], 'stop':[1, 0], 'yes':[2, 0], 'up':[3, 0], 'down':[4, 0], 'left':[5, 0], 'right':[6, 0]}\n",
    "def prep_generated_data():\n",
    "    spectrograms = []\n",
    "    file_names = os.listdir('./data/speech_clips/generated')\n",
    "    np.random.shuffle(file_names)\n",
    "    for file in tqdm(file_names):\n",
    "        data, rate = librosa.load('./data/speech_clips/generated/' + file, duration=1, sr=sr)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128, power=power)\n",
    "        if spectrogram.shape[1] == 32:\n",
    "            command = file.split('_')[0]\n",
    "            if command in commands_with_label:\n",
    "                if commands_with_label[command][1] < 1500:\n",
    "                    spectrograms.append((spectrogram, commands_with_label[command][0]))\n",
    "                    commands_with_label[command][1] += 1\n",
    "\n",
    "    X_train = np.array(spectrograms)\n",
    "    \n",
    "    np.save('./data/speech-commands-generated-data', X_train)\n",
    "    return spectrogram.shape\n",
    "\n",
    "shape = prep_generated_data()\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
