{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapted from https://machinelearningmastery.com/how-to-train-a-progressive-growing-gan-in-keras-for-synthesizing-faces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, AveragePooling2D, Add, Layer\n",
    "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.python.keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, save_model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (28, 28, 1) \n",
    "latent_dim = 100\n",
    "model_sizes = [(7, 7, 1), (14, 14, 1), (28, 28, 1)]\n",
    "batch_size = 64\n",
    "epochs = [10, 20, 30]\n",
    "g_lr = .00002\n",
    "d_lr = .00002\n",
    "label = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./data/fashion/' + label + '-train.npy')\n",
    "# change to shape (28, 28, 1)\n",
    "X_train = np.expand_dims(X_train, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(X_train[np.random.randint(0, X_train.shape[0])]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        images_list.append(new_image)\n",
    "    return np.asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(Add):\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name='ws_alpha')\n",
    "\n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormalization(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    # standardize inputs\n",
    "    def call(self, inputs):\n",
    "        normalized = (inputs - backend.mean(inputs)) / backend.std(inputs)\n",
    "        return inputs\n",
    "\n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator():\n",
    "    model_list = []\n",
    "    \n",
    "    in_image = Input(shape=model_sizes[0])\n",
    "\n",
    "    d = Conv2D(64, (1,1), padding='same')(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(64, (3,3), padding='same')(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(64, (4,4), padding='same')(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "    \n",
    "    model = Model(in_image, out_class)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=Adam(lr=d_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    # create submodels\n",
    "    for i in range(1, len(model_sizes)):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        \n",
    "        # create new model for next resolution\n",
    "        models = add_discriminator_block(old_model, i)\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_discriminator_block(old_model, i, n_input_layers=3):\n",
    "    # get shape of existing model\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    \n",
    "    # define new input shape\n",
    "    input_shape = model_sizes[i]\n",
    "    \n",
    "    in_image = Input(shape=input_shape)\n",
    "   \n",
    "    d = Conv2D(64, (1,1), padding='same')(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(64, (3,3), padding='same')(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Conv2D(64, (3,3), padding='same')(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = AveragePooling2D()(d)\n",
    "    block_new = d\n",
    "    \n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model1 = Model(in_image, d)\n",
    "    model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=d_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    \n",
    "    # downsample the new larger image\n",
    "    downsample = AveragePooling2D()(in_image)\n",
    "    \n",
    "    # connect old input processing to downsampled new input\n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    \n",
    "    # fade in output of old model input layer with new input\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    \n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    # define straight-through model\n",
    "    model2 = Model(in_image, d)\n",
    "    model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=d_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    model_list = []\n",
    "    \n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    g  = Dense(64 * model_sizes[0][0] * model_sizes[0][1])(in_latent)\n",
    "    g = Reshape((model_sizes[0][0], model_sizes[0][1], 64))(g)\n",
    "    \n",
    "    g = Conv2D(64, (3,3), padding='same')(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    g = Conv2D(64, (3,3), padding='same')(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    out_image = Conv2D(1, (1,1), padding='same', activation='sigmoid')(g)\n",
    "    \n",
    "    model = Model(in_latent, out_image)\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    # create submodels\n",
    "    for i in range(1, len(model_sizes)):\n",
    "        # get prior model without the fade-on\n",
    "        old_model = model_list[i - 1][0]\n",
    "        # create new model for next resolution\n",
    "        models = add_generator_block(old_model)\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_generator_block(old_model):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    \n",
    "    # get the end of the last block\n",
    "    block_end = old_model.layers[-2].output\n",
    "    \n",
    "    # upsample, and define new block\n",
    "    upsampling = UpSampling2D()(block_end)\n",
    "    g = Conv2D(64, (3,3), padding='same', )(upsampling)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    g = Conv2D(64, (3,3), padding='same', )(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    out_image = Conv2D(1, (1,1), padding='same', activation='sigmoid')(g)\n",
    "    \n",
    "    model1 = Model(old_model.input, out_image)\n",
    "    \n",
    "    # get the output layer from old model\n",
    "    out_old = old_model.layers[-1]\n",
    "    # connect the upsampling to the old output layer\n",
    "    out_image2 = out_old(upsampling)\n",
    "    # define new output image as the weighted sum of the old and new models\n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    \n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_composite(discriminators, generators):\n",
    "    model_list = []\n",
    "    \n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "        \n",
    "        # straight-through model\n",
    "        d_models[0].trainable = False\n",
    "        model1 = Sequential()\n",
    "        model1.add(g_models[0])\n",
    "        model1.add(d_models[0])\n",
    "        model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=g_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        \n",
    "        # fade-in model\n",
    "        d_models[1].trainable = False\n",
    "        model2 = Sequential()\n",
    "        model2.add(g_models[1])\n",
    "        model2.add(d_models[1])\n",
    "        model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=g_lr, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        \n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    i = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[i]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, n_samples):\n",
    "    noise = np.random.normal(0, 1, (n_samples, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    y = -np.ones((n_samples, 1))\n",
    "    return generated_images, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_fadein(models, step, n_steps):\n",
    "    # calculate current alpha (linear from 0 to 1)\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    # update the alpha for each model\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_models, d_models, gan_models, dataset, latent_dim):\n",
    "    # fit the baseline model\n",
    "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "    \n",
    "    # scale dataset to appropriate size\n",
    "    gen_shape = g_normal.output_shape\n",
    "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "    print('Data Size:', scaled_data.shape)\n",
    "    \n",
    "    # train normal or straight-through models\n",
    "    train_epochs(g_normal, d_normal, gan_normal, scaled_data, epochs[0])\n",
    "    save_images('tuned', gen_shape, g_normal)\n",
    "    \n",
    "    for i in range(1, len(g_models)):\n",
    "        # retrieve models for this level of growth\n",
    "        [g_normal, g_fadein] = g_models[i]\n",
    "        [d_normal, d_fadein] = d_models[i]\n",
    "        [gan_normal, gan_fadein] = gan_models[i]\n",
    "        # scale dataset to appropriate size\n",
    "        gen_shape = g_normal.output_shape\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        print('Data Size:', scaled_data.shape)\n",
    "        # train fade-in models for next level of growth\n",
    "        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, epochs[i], True)\n",
    "        save_images('faded', gen_shape, g_fadein)\n",
    "        # train normal or straight-through models\n",
    "        train_epochs(g_normal, d_normal, gan_normal, scaled_data, epochs[i])\n",
    "        save_images('tuned', gen_shape, g_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, fadein=False):\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = int(dataset.shape[0] / batch_size) * n_epochs\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        # update alpha for all WeightedSum layers when fading in new blocks\n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
    "        \n",
    "        X_real, y_real = generate_real_samples(dataset, batch_size)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, batch_size)\n",
    "        \n",
    "        # update discriminator model\n",
    "        d_loss_real = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss_fake = d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        y_real2 = np.ones((batch_size, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        \n",
    "        # save images every 100 epochs\n",
    "        epoch = i / int(dataset.shape[0] / batch_size)\n",
    "        if epoch % 150 == 0:\n",
    "            if fadein:\n",
    "                save_images('faded' + str(int(epoch)), g_model.output_shape, g_model)\n",
    "                print('dreal=%.3f, dfake=%.3f, g=%.3f' % (d_loss_real, d_loss_fake, g_loss))\n",
    "            else:\n",
    "                save_images('tuned' + str(int(epoch)), g_model.output_shape, g_model)\n",
    "                print('dreal=%.3f, dfake=%.3f, g=%.3f' % (d_loss_real, d_loss_fake, g_loss))\n",
    "        \n",
    "    print('dreal=%.3f, dfake=%.3f, g=%.3f' % (d_loss_real, d_loss_fake, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(status, gen_shape, generator):\n",
    "    rows, cols = 2, 2\n",
    "    noise = np.random.normal(0, 1, (rows * cols, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols)\n",
    "    cnt = 1\n",
    "    for i in range(rows * cols):\n",
    "        plt.subplot(rows, cols, cnt)\n",
    "        plt.imshow(gen_imgs[i, :,:,0])\n",
    "        cnt += 1\n",
    "    name = 'images/%02dx%02d-%s' % (gen_shape[1], gen_shape[2], status)\n",
    "    fig.savefig(name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_models = define_discriminator()\n",
    "g_models = define_generator()\n",
    "gan_models = define_composite(d_models, g_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(g_models, d_models, gan_models, X_train, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "generated_image = g_models[2][0].predict(noise)\n",
    "plt.imshow(np.squeeze(generated_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = g_models[2][0]\n",
    "discriminator = d_models[2][0]\n",
    "gan = gan_models[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(epochs):\n",
    "    g_loss_list = [] \n",
    "    dfake_list = []\n",
    "    dreal_list = []\n",
    "    scaled_data = scale_dataset(X_train, (28, 28, 1))\n",
    "    for epoch in range(epochs):\n",
    "        X_real, y_real = generate_real_samples(scaled_data, batch_size)\n",
    "        X_fake, y_fake = generate_fake_samples(generator, batch_size)\n",
    "        \n",
    "        # update discriminator model\n",
    "        d_loss_real = discriminator.train_on_batch(X_real, y_real)\n",
    "        d_loss_fake = discriminator.train_on_batch(X_fake, y_fake)\n",
    "        acc = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        y_real2 = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(z_input, y_real2)\n",
    "        g_loss_list.append(g_loss)\n",
    "        dreal_list.append(d_loss_real)\n",
    "        dfake_list.append(d_loss_fake)\n",
    "        \n",
    "        if epoch % 150 == 0:\n",
    "            print(str(epoch) + ' dreal=%.5f, dfake=%.5f, g=%.5f' % (d_loss_real, d_loss_fake, g_loss))\n",
    "            save_images('final' + str(epoch), generator.output_shape, generator)\n",
    "                   \n",
    "    return g_loss_list, dreal_list, dfake_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = np.expand_dims(X_train[np.random.randint(0, X_train.shape[0])], axis=0)\n",
    "print(discriminator.predict(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g_loss, fake_loss, real_loss = train_final_model(551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "generated_image = generator.predict(noise)\n",
    "\n",
    "print(discriminator.predict(generated_image))\n",
    "plt.imshow(np.squeeze(generated_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(g_loss))\n",
    "plt.plot(np.abs(fake_loss))\n",
    "plt.plot(np.abs(real_loss))\n",
    "plt.legend(['g_loss', 'fake_loss', 'real_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(n, generator):\n",
    "    noise = np.random.normal(0, 1, (n, latent_dim))\n",
    "    generated_images = np.squeeze(generator.predict(noise))\n",
    "    np.save('data/fashion/' + label + '-generated',  generated_images)\n",
    "    \n",
    "generate_images(1500, generator)    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def prep_data(X, y):\n",
    "    # noramlize to be between 0 and 1\n",
    "    X = X / 255\n",
    "    data_sets = [[] for i in range(10)]\n",
    "    for i, label in enumerate(y):\n",
    "        data_sets[label].append(X[i])\n",
    "\n",
    "    for i, data_set in enumerate(data_sets):\n",
    "        np.save('data/fashion/' + str(i) + '-train',  data_set)\n",
    "    \n",
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "prep_data(X_train, y_train)\n",
    "np.save('data/fashion/X-test',  X_test)\n",
    "np.save('data/fashion/y-test',  y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
