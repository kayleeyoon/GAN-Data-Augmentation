{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import librosa\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = []\n",
    "first = True\n",
    "\n",
    "for filename in tqdm(os.listdir('ravdess')):\n",
    "    split_filename = filename.split('.')\n",
    "    if split_filename[1] == 'wav':\n",
    "        gender_id = int(split_filename[0].split('-')[-1])\n",
    "        # only use female voices\n",
    "        if gender_id % 2 == 0:\n",
    "            data, rate = librosa.load('./ravdess/' + filename, duration=2.5, sr=None)\n",
    "            spectrogram = librosa.feature.melspectrogram(y=data, sr=rate)\n",
    "            if first:\n",
    "                shape = spectrogram.shape\n",
    "                _min = np.amin(spectrogram)\n",
    "                _max = np.amax(spectrogram)\n",
    "                first = False\n",
    "            else:\n",
    "                _min = min(np.amin(spectrogram), _min)\n",
    "                _max = max(np.amax(spectrogram), _max)\n",
    "\n",
    "            emotion = int(filename.split('-')[2]) - 1\n",
    "            spectrograms.append((spectrogram, emotion))\n",
    "    \n",
    "for spectrogram in spectrograms:\n",
    "    (spectrogram - _min) / (_max - _min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(spectrograms)\n",
    "train = spectrograms\n",
    "#test = spectrograms[180:]\n",
    "\n",
    "x_train, y_train = zip(*train)\n",
    "#x_test, y_test = zip(*test)\n",
    "\n",
    "# reshape for CNN\n",
    "x_train = np.array([x.reshape((shape[0], shape[1], 1)) for x in x_train])\n",
    "#x_test = np.array([x.reshape((shape[0], shape[1], 1)) for x in x_test])\n",
    "\n",
    "# reshape for RNN\n",
    "#x_train = np.array([x.reshape((shape[0], shape[1])) for x in x_train])\n",
    "#x_test = np.array([x.reshape((shape[0], shape[1])) for x in x_test])\n",
    "\n",
    "# one hot encode target output\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, num_outputs))\n",
    "#y_test = np.array(keras.utils.to_categorical(y_test, 2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CONVERTING MFCC TO AUDIO (QUALITY IS MUCH WORSE THAN SPECTOGRAM TO AUDIO)\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "test = librosa.feature.inverse.mfcc_to_audio(mfcc, sr=rate)\n",
    "write('test.wav', rate, test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CONVERTING SPECTOGRAM TO AUDIO\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "test = librosa.feature.inverse.mel_to_audio(test, sr=rate)\n",
    "write('test.wav', rate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', strides=(1, 1), padding='same', input_shape=(shape[0], shape[1], 1)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', strides=(1,1), padding='same'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.summary()\n",
    "#adam = keras.optimizers.Adam(lr=0.00001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictionList = []\n",
    "actualList = []\n",
    "for pred in predictions:\n",
    "    predictionList.append(np.argmax(pred))\n",
    "    \n",
    "for actual in y_test:\n",
    "    actualList.append(np.argmax(actual))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(predictionList)):\n",
    "    if predictionList[i] == actualList[i]:\n",
    "        correct += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correct/total"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# shape of data for RNN is (n, time, feat)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(shape[0], shape[1])))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(.5))\n",
    "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(8, activation='relu')))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_outputs, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
